âš™ï¸ Features

âœ… Web scraping using Scrapy
âœ… PDF text extraction using pdfplumber
âœ… Automatic JSON export
âœ… Django backend API endpoints
âœ… Simple UI (index.html) for uploads & scraping

ğŸ§© Folder Structure
smart-data-extractor/
â”‚
â”œâ”€â”€ manage.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Tmy_scrapper/                 # Scrapy spider folder
â”‚   â”œâ”€â”€ spiders/
â”‚   â”‚   â””â”€â”€ generic.py            # Main spider for URL scraping
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ main_app/                     # Django app folder
â”‚   â”œâ”€â”€ views.py                  # Handles requests & API routes
â”‚   â”œâ”€â”€ utils.py                  # Core scraping + PDF functions
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html            # Frontend UI
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ pdf_extracted_data/           # Auto-created for storing PDF JSON files
â””â”€â”€ scrapy_output/                # Auto-created for scraped data

ğŸ’» How to Run It
1ï¸âƒ£ Clone the repo
git clone https://github.com/YOUR_USERNAME/smart-data-extractor.git
cd smart-data-extractor

2ï¸âƒ£ Create & activate virtual environment
python -m venv env
source env/bin/activate     # (Linux/Mac)
env\Scripts\activate        # (Windows)

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Run migrations & start Django server
python manage.py runserver

5ï¸âƒ£ Access the UI

Open: http://127.0.0.1:8000/

ğŸŒ API Endpoints
â–¶ï¸ Web Scraping

POST /scrape_url/



ğŸ§  Tech Stack

Python 3.10+
Django 5+
Scrapy
pdfplumber
HTML + JS (Frontend)
